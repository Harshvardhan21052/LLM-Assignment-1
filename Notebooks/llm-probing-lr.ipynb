{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9361929,"sourceType":"datasetVersion","datasetId":5676463},{"sourceId":3854065,"sourceType":"datasetVersion","datasetId":2290158},{"sourceId":4691480,"sourceType":"datasetVersion","datasetId":2716814}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-11T15:08:56.110689Z","iopub.execute_input":"2024-09-11T15:08:56.111852Z","iopub.status.idle":"2024-09-11T15:08:56.475299Z","shell.execute_reply.started":"2024-09-11T15:08:56.111793Z","shell.execute_reply":"2024-09-11T15:08:56.474327Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/mba-admissions/MBA_ADMISSIONS.csv\n/kaggle/input/petrolgas-prices-worldwide/Petrol Dataset June 23 2022 -- Version 2.csv\n/kaggle/input/petrolgas-prices-worldwide/Petrol Dataset June 20 2022.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:09:33.785701Z","iopub.execute_input":"2024-09-11T15:09:33.786702Z","iopub.status.idle":"2024-09-11T15:09:52.560867Z","shell.execute_reply.started":"2024-09-11T15:09:33.786658Z","shell.execute_reply":"2024-09-11T15:09:52.559938Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error, r2_score","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:19:11.042757Z","iopub.execute_input":"2024-09-11T15:19:11.043168Z","iopub.status.idle":"2024-09-11T15:19:11.048905Z","shell.execute_reply.started":"2024-09-11T15:19:11.043132Z","shell.execute_reply":"2024-09-11T15:19:11.047935Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"file_path = '/kaggle/input/alcohol-consumption-per-capita-2016/alcohol-consumption.csv'  \ndata = pd.read_csv(file_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:12:50.075406Z","iopub.execute_input":"2024-09-11T15:12:50.076183Z","iopub.status.idle":"2024-09-11T15:12:50.089326Z","shell.execute_reply.started":"2024-09-11T15:12:50.076140Z","shell.execute_reply":"2024-09-11T15:12:50.088323Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:12:52.123793Z","iopub.execute_input":"2024-09-11T15:12:52.124173Z","iopub.status.idle":"2024-09-11T15:12:52.161990Z","shell.execute_reply.started":"2024-09-11T15:12:52.124136Z","shell.execute_reply":"2024-09-11T15:12:52.161112Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"            country  total_consumption  recorded_consumption  \\\n0           Estonia               16.9                  15.8   \n1         Lithuania               15.0                  13.8   \n2    Czech Republic               14.3                  12.4   \n3        Seychelles               13.8                  12.4   \n4           Germany               13.4                  11.3   \n..              ...                ...                   ...   \n184      Bangladesh                0.0                   0.0   \n185          Kuwait                0.0                   0.0   \n186           Libya                0.0                   0.0   \n187      Mauritania                0.0                   0.0   \n188         Somalia                0.0                   0.0   \n\n     unrecorded_consumption  beer_percentage  wine_percentage  \\\n0                       1.1             32.7              7.4   \n1                       1.2             43.6              7.3   \n2                       1.4             53.3             21.3   \n3                       1.4             68.9             22.4   \n4                       1.4             52.6             28.4   \n..                      ...              ...              ...   \n184                     0.0              NaN              NaN   \n185                     0.0              NaN              NaN   \n186                     0.0              NaN              NaN   \n187                     0.0              NaN              NaN   \n188                     0.0              NaN              NaN   \n\n     spirits_percentage  other_percentage  2020_projection  2025_projection  \n0                  50.3               9.6             11.5             11.9  \n1                  37.1              12.1             14.4             13.9  \n2                  25.4               0.0             11.2             11.4  \n3                   6.3               2.5             10.4             10.6  \n4                  18.9               0.0             12.8             12.6  \n..                  ...               ...              ...              ...  \n184                 NaN               NaN              0.0              0.0  \n185                 NaN               NaN              0.0              0.0  \n186                 NaN               NaN              0.0              0.0  \n187                 NaN               NaN              0.0              0.0  \n188                 NaN               NaN              0.0              0.0  \n\n[189 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>total_consumption</th>\n      <th>recorded_consumption</th>\n      <th>unrecorded_consumption</th>\n      <th>beer_percentage</th>\n      <th>wine_percentage</th>\n      <th>spirits_percentage</th>\n      <th>other_percentage</th>\n      <th>2020_projection</th>\n      <th>2025_projection</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Estonia</td>\n      <td>16.9</td>\n      <td>15.8</td>\n      <td>1.1</td>\n      <td>32.7</td>\n      <td>7.4</td>\n      <td>50.3</td>\n      <td>9.6</td>\n      <td>11.5</td>\n      <td>11.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lithuania</td>\n      <td>15.0</td>\n      <td>13.8</td>\n      <td>1.2</td>\n      <td>43.6</td>\n      <td>7.3</td>\n      <td>37.1</td>\n      <td>12.1</td>\n      <td>14.4</td>\n      <td>13.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Czech Republic</td>\n      <td>14.3</td>\n      <td>12.4</td>\n      <td>1.4</td>\n      <td>53.3</td>\n      <td>21.3</td>\n      <td>25.4</td>\n      <td>0.0</td>\n      <td>11.2</td>\n      <td>11.4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Seychelles</td>\n      <td>13.8</td>\n      <td>12.4</td>\n      <td>1.4</td>\n      <td>68.9</td>\n      <td>22.4</td>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>10.4</td>\n      <td>10.6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Germany</td>\n      <td>13.4</td>\n      <td>11.3</td>\n      <td>1.4</td>\n      <td>52.6</td>\n      <td>28.4</td>\n      <td>18.9</td>\n      <td>0.0</td>\n      <td>12.8</td>\n      <td>12.6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>Bangladesh</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>Kuwait</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>Libya</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>Mauritania</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>Somalia</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>189 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Number of NaN values in each column before removal:\")\nprint(data.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:12:59.339666Z","iopub.execute_input":"2024-09-11T15:12:59.340398Z","iopub.status.idle":"2024-09-11T15:12:59.347731Z","shell.execute_reply.started":"2024-09-11T15:12:59.340355Z","shell.execute_reply":"2024-09-11T15:12:59.346815Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of NaN values in each column before removal:\ncountry                    0\ntotal_consumption          0\nrecorded_consumption       0\nunrecorded_consumption     0\nbeer_percentage           10\nwine_percentage           10\nspirits_percentage        10\nother_percentage          10\n2020_projection            0\n2025_projection            0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ['HF_TOKEN']=\"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\"\nos.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\"","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:13:35.755627Z","iopub.execute_input":"2024-09-11T15:13:35.756332Z","iopub.status.idle":"2024-09-11T15:13:35.760710Z","shell.execute_reply.started":"2024-09-11T15:13:35.756290Z","shell.execute_reply":"2024-09-11T15:13:35.759619Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" \ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name, load_in_4bit=True, device_map = 'auto')\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:13:54.712713Z","iopub.execute_input":"2024-09-11T15:13:54.713094Z","iopub.status.idle":"2024-09-11T15:15:43.927191Z","shell.execute_reply.started":"2024-09-11T15:13:54.713061Z","shell.execute_reply":"2024-09-11T15:15:43.926295Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f3eabb01e464c41b3e25a529e0ed990"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff6cad72cc434076a7eea42c27c1c766"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60273dccaa6c42eba0acbccf7fe5a444"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddf5f8c3fb2d4f979d3b65fb55ae07fd"}},"metadata":{}},{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9174eee78fc421b984224eea5f4f7a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32bb4c3fe31a47edbe802b066f0b9c48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b55573f2052f4bf88bc16d0ce8986cbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3401ce95e66647458d48da1dfdb4e015"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cb142b7f93542ada92df5c75abf2980"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4d245b232db4c5691a6646e2a7763b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a875113ad1e441afa6548fc9af799b7c"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"LlamaModel(\n  (embed_tokens): Embedding(128256, 4096)\n  (layers): ModuleList(\n    (0-31): 32 x LlamaDecoderLayer(\n      (self_attn): LlamaSdpaAttention(\n        (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n        (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n        (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n        (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (mlp): LlamaMLP(\n        (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n        (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n        (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n        (act_fn): SiLU()\n      )\n      (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n    )\n  )\n  (norm): LlamaRMSNorm((4096,), eps=1e-05)\n  (rotary_emb): LlamaRotaryEmbedding()\n)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:15:47.459249Z","iopub.execute_input":"2024-09-11T15:15:47.460172Z","iopub.status.idle":"2024-09-11T15:15:47.464379Z","shell.execute_reply.started":"2024-09-11T15:15:47.460128Z","shell.execute_reply":"2024-09-11T15:15:47.463392Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def create_prompts(row):\n    return f\"Tell me about {row['country']}.\"\n#Startt\ndef get_final_token_embeddings(hidden_states):\n    final_token_embeddings = [layer[:, -1, :] for layer in hidden_states]\n    return final_token_embeddings\ndef get_hidden_states(outputs):\n    return outputs.hidden_states\ndef get_embeddings(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    # Forward pass\n    with torch.no_grad():\n        outputs = model(**inputs, output_hidden_states=True)\n    hidden_states = get_hidden_states(outputs)  \n    final_token_embeddings = get_final_token_embeddings(hidden_states)\n    return final_token_embeddings, hidden_states\n\nembeddings_list = []\nhidden_states_list = []\n\nfor index, row in tqdm(data.iterrows(), total=data.shape[0]):\n    prompt = create_prompts(row) \n    embeddings, hidden_states = get_embeddings(prompt)\n    embeddings_list.append(embeddings) \n    hidden_states_list.append(hidden_states)\n\nfirst_le = embeddings_list[0][0]  \nmid_le = embeddings_list[0][len(hidden_states_list[0]) // 2]  \nfinal_le = embeddings_list[0][-1] ","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:16:46.492829Z","iopub.execute_input":"2024-09-11T15:16:46.493209Z","iopub.status.idle":"2024-09-11T15:17:49.891922Z","shell.execute_reply.started":"2024-09-11T15:16:46.493171Z","shell.execute_reply":"2024-09-11T15:17:49.890841Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"  0%|          | 0/189 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:435: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n  warnings.warn(\n100%|██████████| 189/189 [01:03<00:00,  2.98it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_first_lel(embeddings_list):\n    l = []\n    for i in range(len(embeddings_list)):\n        l.append(embeddings_list[i][0])\n    return l\n\ndef get_mid_lel(embeddings_list):\n    l = []\n    for i in range(len(embeddings_list)):\n        mid_layer_embeddings = embeddings_list[i][len(embeddings_list[i]) // 2]\n        l.append(mid_layer_embeddings)\n    return l\n\ndef get_final_lel(embeddings_list):\n    l = []\n    for i in range(len(embeddings_list)):\n        l.append(embeddings_list[i][-1])\n    return l\n\nfirst_lel = get_first_lel(embeddings_list)\nmid_lel = get_mid_lel(embeddings_list)\nfinal_lel = get_final_lel(embeddings_list)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:17:55.074808Z","iopub.execute_input":"2024-09-11T15:17:55.076190Z","iopub.status.idle":"2024-09-11T15:17:55.085640Z","shell.execute_reply.started":"2024-09-11T15:17:55.076131Z","shell.execute_reply":"2024-09-11T15:17:55.084614Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"first_lel[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:18:01.041548Z","iopub.execute_input":"2024-09-11T15:18:01.042348Z","iopub.status.idle":"2024-09-11T15:18:01.074540Z","shell.execute_reply.started":"2024-09-11T15:18:01.042296Z","shell.execute_reply":"2024-09-11T15:18:01.073677Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([[-7.9727e-04, -5.1117e-04,  1.6308e-04,  ...,  1.9302e-03,\n         -4.7445e-05,  1.7242e-03]], dtype=torch.float16)"},"metadata":{}}]},{"cell_type":"code","source":"def get_regression_metrics(x_layer_embeddings_list):\n    flattened_embeddings = []\n    for embedding in x_layer_embeddings_list:\n        flattened_array = embedding.flatten().numpy()\n        flattened_embeddings.append(flattened_array)\n    x_layer_embeddings_np = np.array(flattened_embeddings)\n    target_dur = data['total_consumption'].values\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        x_layer_embeddings_np, target_dur, test_size=0.2, random_state=42\n    )\n\n    linear_regressor = LinearRegression()\n    linear_regressor.fit(X_train, y_train)\n    predicted_dur = linear_regressor.predict(X_test)\n    mse = mean_squared_error(y_test, predicted_dur)\n    return mse","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:18:20.173662Z","iopub.execute_input":"2024-09-11T15:18:20.174578Z","iopub.status.idle":"2024-09-11T15:18:20.181121Z","shell.execute_reply.started":"2024-09-11T15:18:20.174533Z","shell.execute_reply":"2024-09-11T15:18:20.180216Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(\"First layer regression mse:\",get_regression_metrics(first_lel))\nprint(\"Middle layer regression mse:\",get_regression_metrics(mid_lel))\nprint(\"Final layer regression mse:\",get_regression_metrics(final_lel))","metadata":{"execution":{"iopub.status.busy":"2024-09-11T15:19:15.286205Z","iopub.execute_input":"2024-09-11T15:19:15.287219Z","iopub.status.idle":"2024-09-11T15:19:15.511383Z","shell.execute_reply.started":"2024-09-11T15:19:15.287158Z","shell.execute_reply":"2024-09-11T15:19:15.510511Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"First layer regression mse: 17.091877666272616\nMiddle layer regression mse: 12.08696867290296\nFinal layer regression mse: 7.623960073370682\n","output_type":"stream"}]}]}