{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers.git\n!pip install git+https://github.com/huggingface/accelerate.git\n!pip install bitsandbytes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-06T17:30:26.185321Z","iopub.execute_input":"2024-09-06T17:30:26.185743Z","iopub.status.idle":"2024-09-06T17:32:08.077575Z","shell.execute_reply.started":"2024-09-06T17:30:26.185693Z","shell.execute_reply":"2024-09-06T17:32:08.076641Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-kbbldem_\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-kbbldem_\n  Resolved https://github.com/huggingface/transformers.git to commit d7b04ea14ddfef04fc110f360e8ea81cfcd1c86a\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.4.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.45.0.dev0) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (2024.7.4)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9679535 sha256=e6503a3cc5e36638df8112bb9ce0d7bc3495dc6e4ef3be0a3de58ff15ed444c1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-tt4tzl73/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.0\n    Uninstalling transformers-4.44.0:\n      Successfully uninstalled transformers-4.44.0\nSuccessfully installed transformers-4.45.0.dev0\nCollecting git+https://github.com/huggingface/accelerate.git\n  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-45m0s_m6\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-45m0s_m6\n  Resolved https://github.com/huggingface/accelerate.git to commit e7e01812dfa06ce10cf229e1806cc973dcb92986\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (0.24.6)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.35.0.dev0) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.35.0.dev0) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.35.0.dev0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.35.0.dev0) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.35.0.dev0) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.35.0.dev0) (1.3.0)\nBuilding wheels for collected packages: accelerate\n  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.35.0.dev0-py3-none-any.whl size=324529 sha256=7cbdef9f44c94b008a52f0cd79520955ec72440478bb385bdcd6589ca188b874\n  Stored in directory: /tmp/pip-ephem-wheel-cache-219lvuc1/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\nSuccessfully built accelerate\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.33.0\n    Uninstalling accelerate-0.33.0:\n      Successfully uninstalled accelerate-0.33.0\nSuccessfully installed accelerate-0.35.0.dev0\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport warnings\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:32:44.873668Z","iopub.execute_input":"2024-09-06T17:32:44.874426Z","iopub.status.idle":"2024-09-06T17:32:49.136061Z","shell.execute_reply.started":"2024-09-06T17:32:44.874383Z","shell.execute_reply":"2024-09-06T17:32:49.135110Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    'sarvamai/OpenHathi-7B-Hi-v0.1-Base',  \n    load_in_4bit=True, # loading the model with 4 bit precision, so as to show the example on Colab GPU\n    device_map='auto'\n)\n# \ntokenizer = AutoTokenizer.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base')\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:32:49.137503Z","iopub.execute_input":"2024-09-06T17:32:49.137905Z","iopub.status.idle":"2024-09-06T17:41:16.892678Z","shell.execute_reply.started":"2024-09-06T17:32:49.137871Z","shell.execute_reply":"2024-09-06T17:41:16.891665Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/667 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6a80b1f4744eb687b06b24dce4d179"}},"metadata":{}},{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18645cb9e7064343851e241cb34acf2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"782fab93d6934fa0be2133f7751f1267"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14ced0a3513248e99737d50e72c2e7c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d9b7a2f6c61482abe4f5101d17f98c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2058cc7fb5fa4c31993be9a8a60c2d27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ff236a9c6354472b78c04fb1327e1b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c909241aaf0433e94c1efe22f4bfd63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/936 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f2370c37f004b7fa872be1b75da4fdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/968k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5989c090194873b88ef9c2460ccf57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8ab6292936c43b599a4975e8b5fd6d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50a58f6dc6a14c96baf3a7ce1e13158b"}},"metadata":{}}]},{"cell_type":"code","source":"generation_config = GenerationConfig(\n    do_sample = True,\n    temperature = 0.2,\n    repetition_penalty = 1.5,\n    max_new_tokens = 200\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:43:26.356693Z","iopub.execute_input":"2024-09-06T17:43:26.357439Z","iopub.status.idle":"2024-09-06T17:43:26.361823Z","shell.execute_reply.started":"2024-09-06T17:43:26.357394Z","shell.execute_reply":"2024-09-06T17:43:26.360779Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"question = \"Who's horse was chetak?\"\ninputs = tokenizer(\"Human: \"+ question +\"\\nAssistant:\", return_tensors=\"pt\")\ninput_ids = inputs[\"input_ids\"].to('cuda')\nwith torch.no_grad():\n    generation_output = model.generate(\n        input_ids=input_ids,\n        attention_mask=torch.ones_like(input_ids),\n        generation_config=generation_config,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-06T18:02:12.215067Z","iopub.execute_input":"2024-09-06T18:02:12.215923Z","iopub.status.idle":"2024-09-06T18:02:12.760952Z","shell.execute_reply.started":"2024-09-06T18:02:12.215882Z","shell.execute_reply":"2024-09-06T18:02:12.760005Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"output_text = tokenizer.decode(generation_output[0].cuda(), skip_special_tokens=True).strip()\nprint(output_text)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T18:02:13.881757Z","iopub.execute_input":"2024-09-06T18:02:13.882657Z","iopub.status.idle":"2024-09-06T18:02:13.888097Z","shell.execute_reply.started":"2024-09-06T18:02:13.882615Z","shell.execute_reply":"2024-09-06T18:02:13.887180Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Human: Who's horse was chetak?\nAssistant: Chettan.\n","output_type":"stream"}]}]}